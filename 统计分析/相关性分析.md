<h2>相关性分析</h2>

<h3>介绍</h3>

　　相关性分析是指对两个或多个具备相关性的变量元素进行分析，从而衡量两个变量因素的相关密切程度。相关性的元素之间需要存在一定的联系或者概率才可以进行相关性分析。相关性分析可以用来验证两个变量间的线性关系，从相关系数r我们可以知道两个变量是否呈线性关系、线性关系的强弱，以及是正相关还是负相关。

　　相关系数：考察两个事物（在数据里我们称之为变量）之间的相关程度。如果有两个变量：X、Y，最终计算出的相关系数的含义可以有如下理解：

　　(1)、当相关系数为0时，X和Y两变量无关系。

　　(2)、当X的值增大（减小），Y值增大（减小），两个变量为正相关，相关系数在0.00与1.00之间。

　　(3)、当X的值增大（减小），Y值减小（增大），两个变量为负相关，相关系数在-1.00与0.00之间。

相关系数的绝对值越大，相关性越强，相关系数越接近于1或-1，相关度越强，相关系数越接近于0，相关度越弱。

<h3>理论知识</h3>

**1.Pearson相关系数**

　　皮尔逊相关也称为积差相关（或积矩相关）是英国统计学家皮尔逊于20世纪提出的一种计算直线相关的方法，是研究变量之间线性相关程度的量。假设有两个变量X、Y，那么两变量间的皮尔逊相关系数可通过以下公式计算：

> 公式一：![image](/uploads/f1dc95ad58d8fe7e101ef811b760217e/image.png)

> 公式二：![image](/uploads/2248a1e9af696d39111e17c535c6cac6/image.png)

> 公式三：![image](/uploads/6792474036dbe8cb3923869dec28efa3/image.png)

> 公式四：![image](/uploads/804814e4954ade1cc78b73e4a237cebb/image.png)

> 以上列出的四个公式等价，其中E是数学期望，cov表示协方差，N表示变量取值的个数。

适用范围:

　　当两个变量的标准差都不为零时，相关系数才有定义，皮尔逊相关系数适用于：

　　(1)、两个变量之间是线性关系，都是连续数据。

　　(2)、两个变量的总体是正态分布，或接近正态的单峰分布。

　　(3)、两个变量的观测值是成对的，每对观测值之间相互独立。

Numpy和Pandas都提供了Pearson相关系数的计算函数，分别为np.corrcoef(）和Pandas.corr()，使用非常方便。

**2.Spearman Rank（斯皮尔曼等级）相关系数**

　　在统计学中，斯皮尔曼等级相关系数以Charles Spearman命名，并经常用希腊字母ρ（rho）表示其值。斯皮尔曼等级相关系数用来估计两个变量X、Y之间的相关性，其中变量间的相关性可以使用单调函数来描述。如果两个变量取值的两个集合中均不存在相同的两个元素，那么，当其中一个变量可以表示为另一个变量的很好的单调函数时（即两个变量的变化趋势相同），两个变量之间的ρ可以达到+1或-1。

　　假设两个随机变量分别为X、Y（也可以看做两个集合），它们的元素个数均为N，两个随即变量取的第i（1<=i<=N）个值分别用Xi、Yi表示。对X、Y进行排序（同时为升序或降序），得到两个元素排行集合x、y，其中元素xi、yi分别为Xi在X中的排行以及Yi在Y中的排行。将集合x、y中的元素对应相减得到一个排行差分集合d，其中di=xi-yi，1<=i<=N。随机变量X、Y之间的斯皮尔曼等级相关系数可以由x、y或者d计算得到，其计算方式如下所示：

> 由排行差分集合d计算而得（公式一）：![image](/uploads/59113b7fd4fd3af629b97f67e3302843/image.png)

> 由排行集合x、y计算而得（斯皮尔曼等级相关系数同时也被认为是经过排行的两个随即变量的皮尔逊相关系数，以下实际是计算x、y的皮尔逊相关系数）（公式二）：![image](/uploads/407c9d3097a6b34b6d1e84a60290eb50/image.png)

适用范围:

　　斯皮尔曼等级相关系数对数据条件的要求没有皮尔逊相关系数严格，只要两个变量的观测值是成对的等级评定资料，或者是由连续变量观测资料转化得到的等级资料，不论两个变量的总体分布形态、样本容量的大小如何，都可以用斯皮尔曼等级相关系数来进行研究。


**3.Kendall Rank（肯德尔等级）相关系数**

　　在统计学中，肯德尔相关系数是以Maurice Kendall命名的，并经常用希腊字母τ（tau）表示其值。肯德尔相关系数是一个用来测量两个随机变量相关性的统计值。一个肯德尔检验是一个无参数假设检验，它使用计算而得的相关系数去检验两个随机变量的统计依赖性。肯德尔相关系数的取值范围在-1到1之间，当τ为1时，表示两个随机变量拥有一致的等级相关性；当τ为-1时，表示两个随机变量拥有完全相反的等级相关性；当τ为0时，表示两个随机变量是相互独立的。

　　假设两个随机变量分别为X、Y（也可以看做两个集合），它们的元素个数均为N，两个随即变量取的第i（1<=i<=N）个值分别用Xi、Yi表示。X与Y中的对应元素组成一个元素对集合XY，其包含的元素为(Xi, Yi)（1<=i<=N）。当集合XY中任意两个元素(Xi, Yi)与(Xj, Yj)的排行相同时（也就是说当出现情况1或2时；情况1：Xi>Xj且Yi>Yj，情况2：Xi<Xj且Yi<Yj），这两个元素就被认为是一致的。当出现情况3或4时（情况3：Xi>Xj且Yi<Yj，情况4：Xi<Xj且Yi>Yj），这两个元素被认为是不一致的。当出现情况5或6时（情况5：Xi=Xj，情况6：Yi=Yj），这两个元素既不是一致的也不是不一致的。这里有三个公式计算肯德尔相关系数的值：

> 公式一：![image](/uploads/d3886730ad1fd6fb53bbed18dd70b960/image.png)

> 其中C表示XY中拥有一致性的元素对数（两个元素为一对）；D表示XY中拥有不一致性的元素对数。

> 注意：这一公式仅适用于集合X与Y中均不存在相同元素的情况（集合中各个元素唯一）。

> 公式二：![image](/uploads/18c69bc4518c0e47189642b6a212c0e6/image.png)

> 注意：这一公式适用于集合X或Y中存在相同元素的情况（当然，如果X或Y中均不存在相同的元素时，公式二便等同于公式一）。其中C、D与公式一中相同；

> ![image](/uploads/c4d516be523cc2e2d03eab187b53aa35/image.png);![image](/uploads/f6ddf2e285ff43603f41598b09f7218e/image.png);![image](/uploads/63fe0c207fe007a88c3a80da27bdccc5/image.png)

> N1、N2分别是针对集合X、Y计算的，现在以计算N1为例，给出N1的由来（N2的计算可以类推）：将X中的相同元素分别组合成小集合，s表示集合X中拥有的小集合数（例如X包含元素：1 2 3 4 3 3 2，那么这里得到的s则为2，因为只有2、3有相同元素），Ui表示第i个小集合所包含的元素数。N2在集合Y的基础上计算而得。

> 公式三：![image](/uploads/924d784691b367db87a43f2109fb7cbe/image.png)

> 注意：这一公式中没有再考虑集合X、或Y中存在相同元素给最后的统计值带来的影响。公式三的这一计算形式仅适用于用表格表示的随机变量X、Y之间相关系数的计算

适用范围 

　　肯德尔相关系数与斯皮尔曼相关系数对数据条件的要求相同。

<h3>python/pyspark样例代码</h3>

> `import numpy as np`

> `import pandas as pd`

> `pd.DataFrame.corr(method='pearson', min_periods=1)`


<h3>参数说明</h3>

> **method**：可选值为{‘pearson’, ‘kendall’, ‘spearman’}

>　　pearson：Pearson相关系数来衡量两个数据集合是否在一条线上面，即针对线性数据的相关系数计算，针对非线性,数据便会有误差。

>　　spearman：非线性的，非正太分析的数据的相关系数

>　　kendall：用于反映分类变量相关性的指标，即针对无序序列的相关系数，非正太分布的数据

> **min_periods**：样本最少的数据量

<h3>适用场景</h3>

　　相关性分析是量化不同因素间变动状况一致程度的重要指标，在样本数据降维（通过消元减少降低模型复杂度，提高模型泛化能力）、缺失值估计、异常值修正等方面发挥着极其重要的作用，是机器学习样本数据预处理的核心工具。