<h2>相关性分析</h2>

<h3>介绍</h3>

　　相关性分析是指对两个或多个具备相关性的变量元素进行分析，从而衡量两个变量因素的相关密切程度。相关性的元素之间需要存在一定的联系或者概率才可以进行相关性分析。

　　相关性分析可以用来验证两个变量间的线性关系，从相关系数r我们可以知道两个变量是否呈线性关系、线性关系的强弱，以及是正相关还是负相关。

<h3>理论知识</h3>

1.相关性分析检验方法

　　层次聚类方法对给定的数据集进行层次的分解，直到满足某种条件为止，传统的层次聚类算法主要分为两大类算法：

　　1）凝聚的层次聚类：AGNES算法 (AGglomerative NESting)==>采用自底向上的策略。最初将每个对象作为一个簇，然后这些簇根据某些准则被一步一步合并，两个簇间的距离可以由这两个不同簇中距离最近的数据点的相似度来确定；聚类的合并过程反复进行直到所有的对象满足簇数目。

　　2）分裂的层次聚类：DIANA算法 (DIvisive ANALysis)==>采用自顶向下的策略。首先将所有对象置于一个簇中，然后按照某种既定的规则逐渐细分为越来越小的簇(比如最大的欧式距离)，直到达到某个终结条件(簇数目或者簇距离达到阈值)。

2.簇间相似度的计算方法

　　合并或拆分层次聚类算法都是基于簇间相似度进行的，每个簇类包含了一个或多个样本点，通常用距离评价簇间或样本间的相似度，即距离越小相似度越高，距离越大相似度越低。因此我们首先假设样本间的距离为：dist(Pi,Pj)，其中Pi，Pj为任意两个样本，下面介绍常用的簇间相似度计算方法：

> 最小距离：也称为单链接算法（single linkage algorithm），含义为簇类C1和C2的距离由该两个簇的最近样本决定，数学表达式写为：

> ![image](/uploads/c8c154838fff0a03a585ba31a30018e6/image.png)

> 最大距离：也称为全链接算法（complete linkage algorithm），含义为簇类C1和C2的距离由该两个簇的最远样本决定，与单链接算法的含义相反，数学表达式写为：

> ![image](/uploads/31a4512f8b25c4e2f2425cdcc62f8375/image.png)

> 平均距离：也称为均链接算法（average-linkage algorithm），含义为簇类C1和C2的距离等于两个簇类所有样本对的距离平均，数学表达式为：

> ![image](/uploads/9a64f2eb4e00bd32a177c3d7355ed6ac/image.png),其中|C1|，|C2|分别表示簇类的样本个数。

> 离差平方和：簇类C1和C2的距离等于两个簇类所有样本对距离平方和的平均，与均链接算法很相似，数学表达式为：

> ![image](/uploads/90f56c4e9f5f5be1e263a68f3aed0308/image.png)

3.样本间距离的计算方法

　　通过上述我们已经知道了如何通过样本间的距离来评估簇间的距离，那么，如何计算样本间的距离，假设样本是n维，常用的距离计算方法有：

> 1）欧拉距离（Euclidean distance）：![image](/uploads/dc23119485f4631769778de0e26bf396/image.png)

> 2）平方欧式距离（Squared Euclidean distance）：![image](/uploads/8582a1b7f6803c5deef5ee3e83b8a4e1/image.png)

> 3）曼哈顿距离（Manhattan distance）：![image](/uploads/31ebcfcf1b82fe0f2665e50ae40cc80c/image.png)

> 4）切比雪夫距离（Chebyshev distance）:![image](/uploads/473497729f4bd091659435c14eaa9a5a/image.png)

> 5）马氏距离（Mahalanobis distance）：![image](/uploads/2138be63300101910b1eedfc473f6441/image.png),其中S为协方差矩阵。

　　对于文本或非数值型的数据，我们常用汉明距离（Hamming distance）和编辑距离（Levenshtein distance）表示样本间的距离。

4.层次聚类的流程

　　凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。 这里给出采用最小距离的凝聚层次聚类算法流程：


> 1：将每个对象看作一类，计算两两之间的最小距离；

> 2：将距离最小的两个类合并成一个新类；

> 3：重新计算新类与所有类之间的距离；

> 4：重复(2)、(3)，直到所有类最后合并成一类。


<h3>python/pyspark样例代码</h3>

> `import numpy as np`

> `import pandas as pd`

> `pd.DataFrame.corr(method='pearson', min_periods=1)`


<h3>参数说明</h3>

> **method**：可选值为{‘pearson’, ‘kendall’, ‘spearman’}

>　　pearson：Pearson相关系数来衡量两个数据集合是否在一条线上面，即针对线性数据的相关系数计算，针对非线性,数据便会有误差。

>　　spearman：非线性的，非正太分析的数据的相关系数

>　　kendall：用于反映分类变量相关性的指标，即针对无序序列的相关系数，非正太分布的数据

> **min_periods**：样本最少的数据量

<h3>适用场景</h3>

　　相关性分析是量化不同因素间变动状况一致程度的重要指标，在样本数据降维（通过消元减少降低模型复杂度，提高模型泛化能力）、缺失值估计、异常值修正等方面发挥着极其重要的作用，是机器学习样本数据预处理的核心工具。