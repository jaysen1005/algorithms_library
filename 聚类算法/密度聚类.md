<h2>密度聚类</h2>

<h3>介绍</h3>

　　DBSCAN，具有噪声的基于密度的聚类方法，是一种很典型的密度聚类算法；这类密度聚类算法一般假定类别可以通过样本分布的紧密程度决定。同一类别的样本，他们之间的紧密相连的，也就是说，在该类别任意样本周围不远处一定有同类别的样本存在。 

<h3>理论知识</h3>

1.DBSCAN密度定义

　　DBSCAN是基于一组邻域来描述样本集的紧密程度的，参数(ϵ, MinPts)用来描述邻域的样本分布紧密程度。其中，ϵ描述了某一样本的邻域距离阈值，MinPts描述了某一样本的距离为ϵ的邻域中样本个数的阈值。
假设我的样本集是D=(x1,x2,...,xm),则DBSCAN具体的密度描述定义如下：

　　 1） ϵ-邻域：对于xj∈D，其ϵ-邻域包含样本集D中与xj的距离不大于ϵ的子样本集，即Nϵ(xj)={xi∈D|distance(xi,xj)≤ϵ}, 这个子样本集的个数记为|Nϵ(xj)|　

　　 2) 核心对象：对于任一样本xj∈D，如果其ϵ-邻域对应的Nϵ(xj)至少包含MinPts个样本，即如果|Nϵ(xj)|≥MinPts，则xj是核心对象。　

　　 3）密度直达：如果xi位于xj的ϵ-邻域中，且xj是核心对象，则称xi由xj密度直达。注意反之不一定成立，即此时不能说xj由xi密度直达, 除非且xi也是核心对象。

　　 4）密度可达：对于xi和xj,如果存在样本样本序列p1,p2,...,pT,满足p1=xi,pT=xj, 且pt+1由pt密度直达，则称xj由xi密度可达。也就是说，密度可达满足传递性。此时序列中的传递样本p1,p2,...,pT−1均为核心对象，因为只有核心对象才能使其他样本密度直达。注意密度可达也不满足对称性，这个可以由密度直达的不对称性得出。

　　 5）密度相连：对于xi和xj,如果存在核心对象样本xk，使xi和xj均由xk密度可达，则称xi和xj密度相连。注意密度相连关系是满足对称性的。

2.DBSCAN密度聚类思想

　　DBSCAN的簇里面可以有一个或者多个核心对象。如果只有一个核心对象，则簇里其他的非核心对象样本都在这个核心对象的ϵ-邻域里；如果有多个核心对象，则簇里的任意一个核心对象的ϵ-邻域中一定有一个其他的核心对象，否则这两个核心对象无法密度可达。这些核心对象的ϵ-邻域里所有的样本的集合组成的一个DBSCAN聚类簇。

　　DBSCAN使用的方法很简单，它任意选择一个没有类别的核心对象作为种子，然后找到所有这个核心对象能够密度可达的样本集合，即为一个聚类簇。接着继续选择另一个没有类别的核心对象去寻找密度可达的样本集合，这样就得到另一个聚类簇。一直运行到所有核心对象都有类别为止。需要注意的是：

　　 1） 一些异常样本点或者说少量游离于簇外的样本点，这些点不在任何一个核心对象在周围，在DBSCAN中，我们一般将这些样本点标记为噪音点。

　　 2) 距离的度量：即如何计算某样本和核心对象样本的距离。在DBSCAN中，一般采用最近邻思想，采用某一种距离度量来衡量样本距离，比如欧式距离。　

　　　　*  欧氏距离(Euclidean distance):

　　　　![image](/uploads/7eda6b0012384d7c6b5543cb5cc2b208/image.png)

　　 3) 某些样本可能到两个核心对象的距离都小于ϵ，但是这两个核心对象由于不是密度直达，又不属于同一个聚类簇，那么如果界定这个样本的类别呢？一般来说，此时DBSCAN采用先来后到，先进行聚类的类别簇会标记这个样本为它的类别。也就是说DBSCAN的算法不是完全稳定的算法。

3.算法过程

> 输入：样本集D={x1,x2,...,xm}，邻域参数(ϵ,MinPts);

> 过程：

> 1：初始化核心对象集合Ω=∅,

> 2：for j=1,2,...,m do

> 3：  确定样本xj的ϵ-邻域子样本集Nϵ(xj)

> 4：  if |Nϵ(Xj)| >= MinPts then

> 5：    将样本 x(j) 加入核心对象集合Ω=Ω⋃{Xj}

> 6：  end if

> 7：end for

> 8：初始化聚类簇数k=0

> 9：初始化未访问样本集合Γ = D

> 10：while Ω ≠ ∅

> 11：  记录当前未访问样本集合Γold =Γ ;

> 12：  随机选取一个核心对象oϵΩ，初始化队列Q={o};

> 13：  Γ = Γ \ {o}

> 14：  while Ω≠∅ do

> 15：    取出队列Q中的首个样本q;

> 16：    if |Nϵ(q)| >= MinPts then

> 17：      令 ∆ = Nϵ(q) ∩ Γ

> 18：      将∆ 中的样本加入队列Q;

> 19:       Γ = Γ \ ∆;

> 20：    end if

> 21：  end while

> 22:  k = k + 1,生成聚类簇 Ck = Γold \ Γ;

> 23:  Ω = Ω \ Ck 

> 24：end while

> 输出：簇划分 C=C1,C2,...,CK

<h3>简单示例</h3>

> 1.导入：`from sklearn.cluster import DBSCAN`;

> 2.创建模型:`model = DBSCAN(eps = eps, min_samples = min_samples,algorithm=algorithm,leaf_size=leaf_size)`

> 3.训练：`km_fit = model.fit(data_in)`

> 4.预测：`y_pre = model.predict(x_test)`

<h3>参数说明</h3>

> eps：半径,同一领域两个样本的最大距离。 [0,1]之间的double类型。 

> min_samples：领域内最小数目,领域内最小数目，大于0的整数。

> algorithm：算法,计算逐点距离并找到最近邻居。可选值有auto，ball_tree，kd_tree，brute。

> leaf_size:叶子大小。

<h3>适用场景</h3>

　　和K-Means，BIRCH这些一般只适用于凸样本集的聚类相比，DBSCAN既可以适用于凸样本集，也可以适用于非凸样本集。
