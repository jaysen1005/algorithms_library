<h2>层次聚类</h2>

<h3>介绍</h3>

　　层次聚类(Hierarchical Clustering)是聚类算法的一种，通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。创建聚类树有自下而上合并和自上而下分裂两种方法。

<h3>理论知识</h3>

1.层次聚类的原理及分类

　　1）层次法（Hierarchicalmethods）先计算样本之间的距离。每次将距离最近的点合并到同一个类。然后，再计算类与类之间的距离，将距离最近的类合并为一个大类。不停的合并，直到合成了一个类。其中类与类的距离的计算方法有：最短距离法，最长距离法，中间距离法，类平均法等。比如最短距离法，将类与类的距离定义为类与类之间样本的最短距离。

　　2）层次聚类算法根据层次分解的顺序分为：自下底向上和自上向下，即凝聚的层次聚类算法和分裂的层次聚类算法（agglomerative和divisive），也可以理解为自下而上法（bottom-up）和自上而下法（top-down）。自下而上法就是一开始每个个体（object）都是一个类，然后根据linkage寻找同类，最后形成一个“类”。自上而下法就是反过来，一开始所有个体都属于一个“类”，然后根据linkage排除异己，最后每个个体都成为一个“类”。这两种路方法没有孰优孰劣之分，只是在实际应用的时候要根据数据特点以及你想要的“类”的个数，来考虑是自上而下更快还是自下而上更快。至于根据Linkage判断“类”的方法就是最短距离法、最长距离法、中间距离法、类平均法等等（其中类平均法往往被认为是最常用也最好用的方法，一方面因为其良好的单调性，另一方面因为其空间扩张/浓缩的程度适中）。为弥补分解与合并的不足，层次合并经常要与其它聚类方法相结合，如循环定位。

　　3）层次聚类中比较新的算法有BIRCH：利用层次方法的平衡迭代规约和聚类主要是在数据量很大的时候使用，而且数据类型是numerical。首先利用树的结构对对象集进行划分，然后再利用其它聚类方法对这些聚类进行优化；ROCK：主要用在categorical的数据类型上；Chameleon：用到的linkage是knn算法，并以此构建一个graph，Chameleon的聚类效果被认为非常强大，比BIRCH好用，但运算复杂度很高，O(n^2)。

2.层次聚类的流程

　　凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。 这里给出采用最小距离的凝聚层次聚类算法流程：


> 1：将每个对象看作一类，计算两两之间的最小距离；

> 2：将距离最小的两个类合并成一个新类；

> 3：重新计算新类与所有类之间的距离；

> 4：重复(2)、(3)，直到所有类最后合并成一类。


<h3>简单示例</h3>

> 1.导入：`from sklearn.cluster import AgglomerativeClustering`;

> 2.创建模型:`ac_model= AgglomerativeClustering(n_clusters=n_clusters, affinity=affinity, linkage=linkage1)`

> 3.训练：`ac_fit = ac_model.fit(data_in)`

> 4.预测：`y_pre = ac_model.predict(x_test)`

<h3>参数说明</h3>

> n_clusters：设置簇的个数,即聚类个数 

> affinity：距离度量方式,可选：euclidean,manhattan,cosine,l1,l2

> linkage：设置判定标准，可选：ward,complete,Average

<h3>适用场景</h3>

　　层次聚类方法适用于具有很多簇，可能连接限制，非欧几里得距离的聚类，比如孤立点的检测分析、气候跃变分析、滑坡灾害危险性分析等。