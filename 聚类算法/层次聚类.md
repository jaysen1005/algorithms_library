<h2>层次聚类</h2>

<h3>介绍</h3>

　　层次聚类(Hierarchical Clustering)是聚类算法的一种，通过计算不同类别数据点间的相似度来创建一棵有层次的嵌套聚类树。在聚类树中，不同类别的原始数据点是树的最低层，树的顶层是一个聚类的根节点。创建聚类树有自下而上合并和自上而下分裂两种方法。

<h3>理论知识</h3>

1.层次聚类的原理及分类

　　层次聚类方法对给定的数据集进行层次的分解，直到满足某种条件为止，传统的层次聚类算法主要分为两大类算法：

　　1）凝聚的层次聚类：AGNES算法 (AGglomerative NESting)==>采用自底向上的策略。最初将每个对象作为一个簇，然后这些簇根据某些准则被一步一步合并，两个簇间的距离可以由这两个不同簇中距离最近的数据点的相似度来确定；聚类的合并过程反复进行直到所有的对象满足簇数目。

　　2）分裂的层次聚类：DIANA算法 (DIvisive ANALysis)==>采用自顶向下的策略。首先将所有对象置于一个簇中，然后按照某种既定的规则逐渐细分为越来越小的簇(比如最大的欧式距离)，直到达到某个终结条件(簇数目或者簇距离达到阈值)。

2.簇间相似度的计算方法

　　合并或拆分层次聚类算法都是基于簇间相似度进行的，每个簇类包含了一个或多个样本点，通常用距离评价簇间或样本间的相似度，即距离越小相似度越高，距离越大相似度越低。因此我们首先假设样本间的距离为：dist(Pi,Pj)，其中Pi，Pj为任意两个样本，下面介绍常用的簇间相似度计算方法：

> 最小距离：也称为单链接算法（single linkage algorithm），含义为簇类C1和C2的距离由该两个簇的最近样本决定，数学表达式写为：

> ![image](/uploads/c8c154838fff0a03a585ba31a30018e6/image.png)

> 最大距离：也称为全链接算法（complete linkage algorithm），含义为簇类C1和C2的距离由该两个簇的最远样本决定，与单链接算法的含义相反，数学表达式写为：

> ![image](/uploads/31a4512f8b25c4e2f2425cdcc62f8375/image.png)

> 平均距离：也称为均链接算法（average-linkage algorithm），含义为簇类C1和C2的距离等于两个簇类所有样本对的距离平均，数学表达式为：

> ![image](/uploads/9a64f2eb4e00bd32a177c3d7355ed6ac/image.png),其中|C1|，|C2|分别表示簇类的样本个数。

> 离差平方和：簇类C1和C2的距离等于两个簇类所有样本对距离平方和的平均，与均链接算法很相似，数学表达式为：

> ![image](/uploads/90f56c4e9f5f5be1e263a68f3aed0308/image.png)

3.样本间距离的计算方法

　　通过上述我们已经知道了如何通过样本间的距离来评估簇间的距离，那么，如何计算样本间的距离，假设样本是n维，常用的距离计算方法有：

> 1）欧拉距离（Euclidean distance）：![image](/uploads/dc23119485f4631769778de0e26bf396/image.png)

> 2）平方欧式距离（Squared Euclidean distance）：![image](/uploads/8582a1b7f6803c5deef5ee3e83b8a4e1/image.png)

> 3）曼哈顿距离（Manhattan distance）：![image](/uploads/31ebcfcf1b82fe0f2665e50ae40cc80c/image.png)

> 4）切比雪夫距离（Chebyshev distance）:![image](/uploads/473497729f4bd091659435c14eaa9a5a/image.png)

> 5）马氏距离（Mahalanobis distance）：![image](/uploads/2138be63300101910b1eedfc473f6441/image.png),其中S为协方差矩阵。

> 对于文本或非数值型的数据，我们常用汉明距离（Hamming distance）和编辑距离（Levenshtein distance）表示样本间的距离。

4.层次聚类的流程

　　凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。 这里给出采用最小距离的凝聚层次聚类算法流程：


> 1：将每个对象看作一类，计算两两之间的最小距离；

> 2：将距离最小的两个类合并成一个新类；

> 3：重新计算新类与所有类之间的距离；

> 4：重复(2)、(3)，直到所有类最后合并成一类。


<h3>python/pyspark样例代码</h3>

> 1.导入：`from sklearn.cluster import AgglomerativeClustering`;

> 2.创建模型:`ac_model= AgglomerativeClustering(n_clusters=n_clusters, affinity=affinity, linkage=linkage1)`

> 3.训练：`ac_fit = ac_model.fit(data_in)`

> 4.预测：`y_pre = ac_model.predict(x_test)`

<h3>参数说明</h3>

> n_clusters：设置簇的个数,即聚类个数 

> affinity：距离度量方式,可选：euclidean,manhattan,cosine,l1,l2

> linkage：设置判定标准，可选：ward,complete,Average

<h3>适用场景</h3>

　　层次聚类方法适用于具有很多簇，可能连接限制，非欧几里得距离的聚类，比如孤立点的检测分析、气候跃变分析、滑坡灾害危险性分析等。